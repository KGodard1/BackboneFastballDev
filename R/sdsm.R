#' The Poisson Binomial Distribution
#'
#' `ppoibin` is a function from the now archived package poibin.
#'     It computes the cdf, pmf, quantile function, and random number generation for the
#'     Poisson Binomial Distribution.
#'
#' @param kk The values where the cdf or pmf to be evaluated.
#' @param pp The vector for `p_j`'s which are the success probabilities for indicators.
#' @param method "DFT-CF" for the DFT-CF method, "RF" for the recursive formula, "RNA" for the refined normal approximation, "NA" for the normal approximation, and "PA" for the Poisson approximation.
#' @param wts The weights for `p_j`'s.
#'
#' @details The `poibin` package was created by Yili Hong (2013). Since the package has been archived, the ppoibin function source code is used in the sdsm function, via GPL-2 license agreement. The reference to Hong's paper is below.
#' @details The function is used in the \link[backbone]{sdsm} function.
#' @references \href{https://linkinghub.elsevier.com/retrieve/pii/S0167947312003568}{Hong, Yili (2013). On computing the distribution function of the Poisson binomial distribution. Computational Statistics & Data Analysis, Vol. 59, pp. 41-51. DOI: 10.1016/j.csda.2012.10.006}
#' @return the entire cdf, pmf, quantiles, and random numbers
ppoibin <- function (kk, pp, method = "RNA", wts = NULL) {
  if (any(pp < 0) | any(pp > 1)) {
    stop("invalid values in pp.")
  }
  if (is.null(wts)) {
    wts = rep(1, length(pp))
  }
  switch(method, `DFT-CF` = {
    mm = length(kk)
    res = double(mm)
    npp = length(pp)
    n = sum(wts)
    avec = double(n + 1)
    bvec = double(n + 1)
    funcate = 1
    ex = 0
    tmp = .C("multi_bin_dft_cf", as.double(res), as.integer(kk),
             as.integer(mm), as.integer(n), as.double(pp), as.double(avec),
             as.double(bvec), as.integer(funcate), as.double(ex),
             as.integer(npp), as.integer(wts), PACKAGE = "backbone")
    res = tmp[[1]]
    res[res < 0] = 0
    res[res > 1] = 1
    res[kk < 0] = 0
    res[kk >= sum(wts)] = 1
  }, RF = {
    kk1 = kk
    kk[kk < 0] = 0
    pp = rep(pp, wts)
    mm = length(kk)
    res = double(mm)
    n = length(pp)
    mat = rep(0, (n + 1) * (n + 2))
    tmp = .C("multi_bin_bh", as.double(res), as.integer(kk),
             as.integer(mm), as.integer(n), as.double(pp), as.double(mat),
             PACKAGE = "backbone")
    res = tmp[[1]]
    res[kk1 < 0] = 0
    res[kk1 >= sum(wts)] = 1
  }, RNA = {
    pp = rep(pp, wts)
    muk = sum(pp)
    sigmak = sqrt(sum(pp * (1 - pp)))
    gammak = sum(pp * (1 - pp) * (1 - 2 * pp))
    ind = gammak/(6 * sigmak^3)
    kk1 = (kk + 0.5 - muk)/sigmak
    vkk.r = stats::pnorm(kk1) + gammak/(6 * sigmak^3) * (1 - kk1^2) *
      stats::dnorm(kk1)
    vkk.r[vkk.r < 0] = 0
    vkk.r[vkk.r > 1] = 1
    res = vkk.r
  }, `NA` = {
    pp = rep(pp, wts)
    muk = sum(pp)
    sigmak = sqrt(sum(pp * (1 - pp)))
    gammak = sum(pp * (1 - pp) * (1 - 2 * pp))
    kk1 = (kk + 0.5 - muk)/sigmak
    res = stats::pnorm(kk1)
  }, PA = {
    pp = rep(pp, wts)
    muk = sum(pp)
    res = stats::ppois(q = kk, lambda = muk)
  })
  return(res)
}


#' The stochastic degree sequence model (sdsm)
#'
#' `sdsm` computes the proportion of generated edges
#'     above or below the observed value using the stochastic degree sequence model.
#'     Once computed, use \code{\link{backbone.extract}} to return
#'     the backbone matrix for a given alpha value. The `sdsm` function uses the
#'    `ppoibin` function source code and C code from the archived `poibin` package,
#'    created by Yili Hong (2013).
#'
#' @param B Matrix: Bipartite adjacency matrix
#' @param trials Integer: Number of random bipartite graphs generated. Default is 0.
#' @param model String: A generalized linear model (glm) used to generate random bipartite graphs.
#' @param sparse Boolean: If sparse matrix manipulations should be used
#' @param maxiter Integer: Maximum number of iterations if "model" is a glm.
#' @param dyad vector length 2: two row entries i,j. Saves each value of the i-th row and j-th column in each projected B* matrix. This is useful for visualizing an example of the empirical null edge weight distribution generated by the model. These correspond to the row and column indices of a cell in the projected matrix , and can be written as their string row names or as numeric values.
#' @param alpha Real: proposed alpha threshold to be used for determining statistical significance of edges
#' @param tolerance Real: tolerance for p-value computation using RNA poisson-binomial approximation
#' @param progress Boolean: If \link[utils]{txtProgressBar} should be used to measure progress
#'
#' @details The 'model' parameter can take in a 'link' function, as described by \link[stats]{glm} and \link[stats]{family}. This can be one of c('logit', 'probit', 'cauchit', 'log', 'cloglog').
#' @details If 'trials'>0, the function uses repeat Bernoulli trials to compute the proportions, using the following steps:
#' During each iteration, sdsm computes a new B* matrix using probabilities computed using the `glm`. This is a random bipartite matrix with about the same row and column sums as the original matrix B.
#' If the dyad_parameter is indicated to be used in the parameters, when the B* matrix is projected, the projected value for the corresponding row and column will be saved.
#' This allows the user to see the distribution of the edge weights for desired row and column.
#' @details If 'trials'=0, the proportion of edges above or below the observed values are computed using the Poisson Binomial distribution.
#' These values are approximated using either a Discrete Fourier Transform (DFT method) or a Refined Normal Approximation (RNA method). These functions are described by the now archived `poibin` package.
#' The RNA method is used by default, unless the computed value is within the margin of 'alpha'-'tolerance' and 'alpha'+'tolerance', the DFT method is used.
#' @details The `poibin` package was created by Yili Hong (2013). Since the package has been archived, the ppoibin function source code is used in the sdsm function, via GPL-2 license agreement. The reference to Hong's paper is below.
#'
#'
#' @return list(positive, negative, dyad_values, summary).
#' positive: matrix of proportion of times each entry of the projected matrix B is above the corresponding entry in the generated projection.
#' negative: matrix of proportion of times each entry of the projected matrix B is below the corresponding entry in the generated projection.
#' dyad_values: list of edge weight for i,j in each generated projection, included if 'dyad' not NULL and 'trials > 0'.
#' summary: a data frame summary of the inputted matrix and the model used including: model name, number of rows, skew of row sums, number of columns, skew of column sums, and running time.
#'
#' @references \href{https://www.sciencedirect.com/science/article/abs/pii/S0378873314000343}{Neal, Z. P. (2014). The backbone of bipartite projections: Inferring relationships from co-authorship, co-sponsorship, co-attendance, and other co-behaviors. Social Networks, 39, Elsevier: 84-97. DOI: 10.1016/j.socnet.2014.06.001}
#' @references \href{https://linkinghub.elsevier.com/retrieve/pii/S0167947312003568}{Hong, Yili (2013). On computing the distribution function of the Poisson binomial distribution. Computational Statistics & Data Analysis, Vol. 59, pp. 41-51. DOI: 10.1016/j.csda.2012.10.006}
#'
#'
#' @export
#'
#' @examples
#'sdsm_bt <- sdsm(davis, trials = 100,dyad = c("EVELYN", "CHARLOTTE" ))
#'sdsm_rna <- sdsm(davis, trials = 0, tolerance = 0)
#'sdsm_dft <- sdsm(davis, trials = 0, tolerance = 1)
sdsm <- function(B,
                 trials = 0,
                 model = "logit",
                 sparse = TRUE,
                 maxiter = 25,
                 dyad = NULL,
                 alpha = 0.05,
                 tolerance = 0,
                 progress = FALSE){

  #Argument Checks
  if ((sparse!="TRUE") & (sparse!="FALSE")) {stop("sparse must be either TRUE or FALSE")}
  if ((model!="logit") & (model!="probit") & (model!="log") & (model!="cloglog")) {stop("model must be: logit | probit | log | cloglog")}
  if ((trials < 0) | (trials%%1!=0)) {stop("trials must be a non-negative integer")}
  if (!(methods::is(B, "matrix")) & !(methods::is(B, "sparseMatrix"))) {stop("input bipartite data must be a matrix")}

  #If sparse matrix input, use sparse matrix operations
  if (methods::is(B, "sparseMatrix")) {sparse <- TRUE}

  #Run Time
  run.time.start <- Sys.time()

  #Project to one-mode data
  if (sparse=="TRUE") {
    if (!methods::is(B, "sparseMatrix")) {
      B <- Matrix::Matrix(B, sparse = T)
    }
    P <- Matrix::tcrossprod(B)
  } else {
    P <- tcrossprod(B)
  }

  #Create Positive and Negative Matrices to hold backbone
  Positive <- matrix(0, nrow(P), ncol(P))
  Negative <- matrix(0, nrow(P), ncol(P))

  #Compute probabilities for SDSM (alternative is in star)
  #Vectorize the bipartite data
  A <- data.frame(as.vector(B))
  names(A)[names(A)=="as.vector.B."] <- "value"

  #Assign row and column IDs in the vectorized data
  A$row <- rep(1:nrow(B), times=ncol(B))
  A$col <- rep(1:ncol(B), each=nrow(B))

  #Compute and attach rowsums, columnsums, interact
  A$rowmarg <- stats::ave(A$value,A$row,FUN=sum)
  A$colmarg <- stats::ave(A$value,A$col,FUN=sum)
  A$rowcol<-A$rowmarg*A$colmarg

  #Estimate logit model, compute probabilities
  if (requireNamespace("speedglm", quietly = TRUE)){
    model.estimates <- speedglm::speedglm(formula= value ~  rowmarg + colmarg + rowcol, family = stats::binomial(link=model), data=A, control = list(maxit = maxiter))
    probs <- as.vector(stats::predict(model.estimates,newdata=A,type = "response"))
  } else {
    model.estimates <- stats::glm(formula= value ~  rowmarg + colmarg + rowcol, family = stats::binomial(link=model), data=A, control = list(maxit = maxiter))
    probs <- as.vector(stats::predict(model.estimates,newdata=A,type = "response"))
  }

  #Assemble and compute probabilities
  prob.mat <- matrix(probs, nrow = nrow(B), ncol = ncol(B))  #Probability matrix
  rows <- dim(prob.mat)[1]

  #Monte Carlo Method
  if (trials > 0){
    #Dyad save
    edge_weights <- numeric(trials)
    if (length(dyad) > 0){
      if (class(dyad[1]) != "numeric"){
        vec <- match(c(dyad[1], dyad[2]), rownames(B))
      }
      else{
        vec <- dyad
      }
    }

    #Build null models
    for (i in 1:trials){

      #Start estimation timer; print message
      if (i == 1) {
        start.time <- Sys.time()
        message("Finding the Backbone using ", model, " SDSM")
      }

      #Use GLM probabilities to create an SDSM Bstar
      #Bstar <- matrix(rbinom(nrow(B) * ncol(B), 1, probs), nrow(B), ncol(B))  #Equivalent, but slightly slower
      Bstar <- matrix(((stats::runif(nrow(B) * ncol(B)))<=probs)+0, nrow(B), ncol(B))
      if (sparse=="TRUE") {Bstar <- Matrix::Matrix(Bstar,sparse=T)}


      #Construct Pstar from Bstar
      if (sparse=="TRUE") {
        Pstar <- Matrix::tcrossprod(Bstar)
      } else {
        Pstar <- tcrossprod(Bstar)
      }

      #Check whether Pstar edge is larger/smaller than P edge
      Positive <- Positive + (Pstar >= P)+0
      Negative <- Negative + (Pstar <= P)+0

      #Save Dyad of P
      if (length(dyad) > 0){
        edge_weights[i] <- Pstar[vec[1], vec[2]]
      }

      #Report estimated running time, update progress bar
      if (i==10){
        end.time <- Sys.time()
        est = (round(difftime(end.time, start.time), 2) * (trials/10))
        message("Estimated time to complete is ", est," ", units(est))
        if (progress == "TRUE"){
          pb <- utils::txtProgressBar(min = 0, max = trials, style = 3)
        }
      } #end timer estimate

      if ((progress == "TRUE") & (i>=10)) {utils::setTxtProgressBar(pb, i)}
    } #end for loop
    if (progress == "TRUE"){close(pb)}

    #Proporition of greater than expected and less than expected
    Positive <- (Positive/trials)
    Negative <- (Negative/trials)
    rownames(Positive) <- rownames(B)
    colnames(Positive) <- rownames(B)
    rownames(Negative) <- rownames(B)
    colnames(Negative) <- rownames(B)

    #Save Dyad of P
    if (length(dyad) == 0){
      edge_weights <- NULL
    }
  } #end if trials > 0

  # Poisson Binomial Distribution Method
  if (trials == 0){
    message("Finding the Backbone using Poisson Binomial SDSM with alpha = ", alpha, " and tolerance = ", tolerance)
    for (i in 1:rows){
      #Compute prob.mat[i,]*prob.mat[j,] for each j
      prob.imat <- sweep(prob.mat, MARGIN = 2, prob.mat[i,], `*`)

      #Find cdf, below or equal to value for negative, above or equal to value for positive
      #Using RNA approximation
      negative <- as.array(mapply(ppoibin, kk= as.data.frame(t(P[i,])), pp = as.data.frame(t(prob.imat)), method = "RNA"))
      positive <- as.array((1- mapply(ppoibin, kk=(as.data.frame(t(P[i,])-1)), pp = as.data.frame(t(prob.imat)), method = "RNA")))

      #Find which values are within a tolerance distance from alpha
      wn <- as.vector(which((negative > (alpha - tolerance)) & (negative < (alpha + tolerance)), arr.ind = TRUE))
      wp <- as.vector(which((positive > (alpha - tolerance)) & (positive < (alpha + tolerance)), arr.ind = TRUE))

      #Change these values to DFT approximation
      if (length(wn)>1){
        dft.negative <- as.array(mapply(ppoibin, kk = as.data.frame(t(P[i,wn])), pp = as.data.frame(t(prob.imat[wn,])), method = "DFT-CF"))
        negative[wn] <- dft.negative
      }
      if (length(wp)>1){
        dft.positive <- as.array((1 - mapply(ppoibin, kk = as.data.frame(t(P[i, wp])-1), pp = as.data.frame(t(prob.imat[wp,])), method = "DFT-CF")))
        positive[wp] <- dft.positive
      }
      if (length(wn)==1){
        dft.negative <- ppoibin(kk = as.data.frame(t(P[i,wn])), pp = as.data.frame(t(prob.imat[wn,])), method = "DFT-CF")
        negative[wn] <- dft.negative
      }
      if (length(wp)==1){
        dft.positive <- 1 - ppoibin(kk = as.data.frame(t(P[i, wp])-1), pp = as.data.frame(t(prob.imat[wp,])), method = "DFT-CF")
        positive[wp] <- dft.positive
      }

      #Set values in Positive & Negative matrices
      Positive[i,] <- positive
      Negative[i,] <- negative
    } #end for i in rows
    rownames(Positive) <- rownames(B)
    colnames(Positive) <- rownames(B)
    rownames(Negative) <- rownames(B)
    colnames(Negative) <- rownames(B)
  } #end if trials == 0

  #Run Time
  run.time.end <- Sys.time()
  total.time = (round(difftime(run.time.end, run.time.start), 2))

  #Compile Summary
  if (sparse=="TRUE") {
    r <- Matrix::rowSums(B)
    c <- Matrix::colSums(B)
    } else {
    r <- rowSums(B)
    c <- colSums(B)
    }

  a <- c("Model", "Number of Rows", "Skew of Row Sums", "Number of Columns", "Skew of Column Sums", "Running Time")
  b <- c("Stochastic Degree Sequence Model", dim(B)[1], round((sum((r-mean(r))**3))/((length(r))*((stats::sd(r))**3)), 5), dim(B)[2], round((sum((c-mean(c))**3))/((length(c))*((stats::sd(c))**3)), 5), as.numeric(total.time))
  model.summary <- data.frame(a,b, row.names = 1)
  colnames(model.summary)<-"Model Summary"

  if ((length(dyad) > 0)&(trials > 0)){
    return(list(positive = Positive, negative = Negative, dyad_values = edge_weights, summary = model.summary))
  }

  else {
    return(list(positive = Positive, negative = Negative, summary = model.summary))
  }

} #end sdsm function

